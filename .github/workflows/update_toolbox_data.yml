name: Update Toolbox Data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 9 * * *"

permissions:
  contents: write

concurrency:
  group: update-toolbox-data
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      # If you don't have a package-lock.json, npm ci will fail.
      - name: Install deps (scraper)
        working-directory: scraper
        run: npm install

      - name: Install Playwright Chromium
        working-directory: scraper
        run: npx playwright install --with-deps chromium

      - name: Ensure data folder exists
        run: mkdir -p data

      # --- SCRAPE (best effort; do NOT fail the whole workflow if Toolbox changes) ---
      - name: Scrape Toolbox items (WS) - best effort
        run: node scraper/scrape_toolbox_items_from_ws.mjs || true

      # --- DEBUG: list + quick peek ---
      - name: Debug: show data folder contents
        if: always()
        run: |
          echo "=== data/ (ls) ==="
          ls -la data || true
          echo "=== data/ sizes ==="
          wc -c data/*.json 2>/dev/null || true
          echo "=== toolbox.items.json head ==="
          if [ -f data/toolbox.items.json ]; then
            head -c 600 data/toolbox.items.json; echo
          else
            echo "data/toolbox.items.json not found"
          fi

      # --- NORMALIZE ONLY IF toolbox.items.json has >= 50 items ---
      - name: Normalize toolbox.items.json -> catalog (only if items >= 50)
        run: |
          if [ ! -s data/toolbox.items.json ]; then
            echo "Skipping normalize: data/toolbox.items.json missing or empty"
            exit 0
          fi

          COUNT=$(node -e "const fs=require('fs'); const j=JSON.parse(fs.readFileSync('data/toolbox.items.json','utf8')); const arr=Array.isArray(j)?j:(Array.isArray(j.items)?j.items:[]); console.log(arr.length);")
          echo "toolbox.items.json item count = $COUNT"

          if [ "$COUNT" -lt 50 ]; then
            echo "Skipping normalize: too few items ($COUNT). Keeping existing outputs."
            exit 0
          fi

          node scraper/normalize_toolbox_items.mjs

      # Optional: if you use this builder, only run if inputs exist
      - name: Build clean catalog (only if needed inputs exist)
        run: |
          if [ -s data/catalog.toolbox.json ] || [ -s data/catalog.clean.json ]; then
            node scraper/build_clean_catalog.mjs || true
          else
            echo "Skipping build_clean_catalog: no catalog inputs found"
          fi

      # --- Upload artifacts even if scraping fails so you can inspect on phone ---
      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: toolbox-debug
          path: |
            data/*.json
            data/*.html
            data/*.png
            data/*.txt
          if-no-files-found: ignore
          retention-days: 7

      # --- Commit only if something changed ---
      - name: Commit generated data (if changed)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/ || true
          git diff --cached --quiet || git commit -m "Update toolbox data"

      # --- Push (safe) ---
      - name: Push changes (safe)
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          set -e
          if [ -z "$GH_PAT" ]; then
            echo "GH_PAT secret is missing"
            exit 1
          fi

          git remote set-url origin "https://x-access-token:${GH_PAT}@github.com/TheRealNodder/Evertale-Optimizer.git"
          git fetch origin main

          git pull --rebase origin main
          git push origin HEAD:main