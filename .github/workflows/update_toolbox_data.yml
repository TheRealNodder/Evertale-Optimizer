name: Update Toolbox Data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 9 * * *"

permissions:
  contents: write

concurrency:
  group: update-toolbox-data
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install deps (scraper)
        working-directory: scraper
        run: npm install

      - name: Install Playwright Chromium
        working-directory: scraper
        run: npx playwright install --with-deps chromium

      - name: Ensure data folder exists
        run: mkdir -p data

      # ---- SCRAPE (best-effort; do not fail run) ----
      - name: Scrape Explorer (captures) - best effort
        run: node scraper/scrape_explorer_capture_json.mjs || true

      - name: Scrape Viewer (captures) - best effort
        run: node scraper/scrape_viewer_characters_playwright.mjs || true

      # Your “full units” scraper (this is where your error was)
      - name: Scrape Toolbox Units Full (HTML) - best effort
        run: node scraper/scrape_toolbox_units_full.mjs || true

      # If you have toolbox WS item scraper, run it best-effort
      - name: Scrape Toolbox Items from WS - best effort
        run: |
          if [ -f scraper/scrape_toolbox_items_from_ws.mjs ]; then
            node scraper/scrape_toolbox_items_from_ws.mjs || true
          else
            echo "skip: scraper/scrape_toolbox_items_from_ws.mjs not found"
          fi

      # ---- NORMALIZE / BUILD (should not fail if inputs missing) ----
      - name: Normalize Toolbox Items - best effort
        run: |
          if [ -f scraper/normalize_toolbox_items.mjs ]; then
            node scraper/normalize_toolbox_items.mjs || true
          else
            echo "skip: scraper/normalize_toolbox_items.mjs not found"
          fi

      - name: Normalize DOM Catalog - best effort
        run: |
          if [ -f scraper/normalize_dom_catalog.mjs ]; then
            node scraper/normalize_dom_catalog.mjs || true
          else
            echo "skip: scraper/normalize_dom_catalog.mjs not found"
          fi

      - name: Build Clean Catalog - required
        run: node scraper/build_clean_catalog.mjs

      # ---- DEBUG VISIBILITY ----
      - name: Show data folder contents
        if: always()
        run: |
          echo "=== data/ ==="
          ls -la data || true
          echo "=== sizes ==="
          wc -c data/*.json 2>/dev/null || true

      - name: Validate clean catalog JSON
        run: node -e "JSON.parse(require('fs').readFileSync('data/catalog.clean.json','utf8')); console.log('catalog.clean.json OK');"

      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: toolbox-debug
          path: |
            data/*.json
            data/*.html
            data/*.png
            data/*.txt
          if-no-files-found: ignore
          retention-days: 7

      # ---- COMMIT ONLY WHAT THE WEBSITE NEEDS ----
      - name: Remove noisy debug files before commit
        run: |
          rm -f data/_debug* || true
          rm -f data/*.png data/*.html data/*.txt || true

      - name: Commit clean catalog only
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/catalog.clean.json || true
          git diff --cached --quiet || git commit -m "Update toolbox catalog"

      - name: Push changes
        run: git push